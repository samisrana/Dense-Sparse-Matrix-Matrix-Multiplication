# Dense and Sparse Matrix Multiplication with Multi-threading, SIMD, and Cache Optimization

## Table of Contents
1. [Introduction](#introduction)
2. [Project Features](#project-features)
3. [Setup Instructions](#setup-instructions)
4. [Dependencies](#dependencies)
5. [Code Structure](#code-structure)
6. [How to Run the Experiments](#how-to-run-the-experiments)
7. [Experiments and Results](#experiments-and-results)  
   - [Optimization Impact](#optimization-impact)  
   - [Dense-Dense Matrix Multiplication](#dense-dense-matrix-multiplication)  
   - [Sparse-Sparse Matrix Multiplication](#sparse-sparse-matrix-multiplication)  
   - [Dense-Sparse Matrix Multiplication](#dense-sparse-matrix-multiplication)
8. [Final Analysis and Conclusions](#final-analysis-and-conclusions)
9. [Future Implementations](#future-implementations)

---

## Introduction
This project implements high-performance **dense-dense, dense-sparse, and sparse-sparse matrix multiplication** using C++ with configurable **multi-threading, SIMD optimizations**, and **cache miss minimization techniques**. The software allows you to experiment with **arbitrary matrix sizes** and sparsity levels, providing flexibility to analyze performance for different configurations.

Matrix multiplication is a critical operation in many fields such as **machine learning, computer vision, and scientific computing**. This project provides tools to evaluate how various optimization techniques impact performance under different matrix sizes and sparsities.

---

## Project Features
- **Arbitrary Matrix Sizes:** Supports matrix sizes larger than the cache capacity (e.g., up to **10,000 x 10,000**).
- **Configurable Multi-threading:** Users can specify the **number of threads** to utilize.
- **Configurable SIMD Optimizations:** SIMD-based multiplication can be enabled or disabled.
- **Configurable Cache Optimization:** Cache blocking and access pattern optimizations are tunable.
- **Thread Configuration:** Users can easily modify the **number of threads** to measure performance scalability.

---

## Setup Instructions

### Installation
1. **Clone the Repository:**
   ```bash
   git clone https://github.com/samisrana/Dense-Sparse-Matrix-Matrix-Multiplication.git
   cd Dense-Sparse-Matrix-Matrix-Multiplication

## Dependencies

The following dependencies are required to build, run, and analyze the project:

### Build Dependencies
- **C++ Compiler:** `g++` with AVX/AVX2 support for SIMD operations.
- **CMake:** (Optional) To manage the build process.

### Performance Tools
- **perf:** A Linux performance analysis tool to gather performance metrics such as cache misses, CPU cycles, and thread utilization.

### Python Libraries
For visualization and analysis of results:
- **matplotlib:** `pip install matplotlib`  
- **seaborn:** `pip install seaborn`
- **pandas** `pip install pandas`
### Operating System
- **Linux:** Recommended for multi-threading and performance measurement compatibility with `perf`.

Make sure all dependencies are properly installed before proceeding with the experiments.
## Code Structure

### Key Components

1. **Makefile**  
   - Automates the **build process**, compiling all necessary source files into object files and the final executable.

2. **include/**  
   - Contains **header files** that define the interfaces for matrix operations and optimizations.
   - **matrix_gen.h:** Declares functions for generating matrices of various sizes and sparsities.  
   - **multiplication.h:** Declares functions for matrix multiplication with options for optimizations.  
   - **optimizations/:** Contains headers for **cache** and **SIMD optimizations**.

3. **src/**  
   - Contains **source files** with the implementation of matrix operations and optimizations.
   - **matrix_gen.cpp:** Implements logic for generating random or sparse matrices.  
   - **multiplication.cpp:** Implements matrix multiplication algorithms with support for **native** and **optimized paths**.  
   - **optimizations/:** Contains implementations for **cache optimization** and **SIMD operations**.

4. **scripts/**  
   - **resultsplot.py:** Visualizes experimental results using Python libraries like `matplotlib` and `seaborn`.  
   - **test.sh:** Runs the complete set of experiments (including native multiplication for large matrices).  
     **Note:** This script may take several hours to complete.  
   - **test_cache_vs_native.sh:** Compares the performance of **cache-optimized** vs **native multiplication**.

5. **performance_results.csv**  
   - Stores the **results** from the experiments, including metrics like **execution time** and **cache misses**.

6. **Executable and Object Files**  
   - **matrix_mult:** The final executable for matrix multiplication, generated by the Makefile.  
   - **Object Files:** Intermediate compiled files such as `matrix_gen.o` and `cache_optimization.o` are created during the build process.

7. **main.cpp**
   - **Main C program** in which asks for type of multiplication, sparsity percentage of sparse matrix if asked, size of matrices, how many threads needed, and which optimizations to turn on/off. Also requires arguement to print or not print output.

8. **multiply.sh**  
   - **Bash script** to run Makefile and run main.cpp with print flag on.

9. **test.sh**  
   - **Bash script** to automate the matrix multiplication experiments. It runs the main.cpp executable (print flag off) with various configurations and collects performance data.

## How to Run the Experiments

To run the full set of experiments, use the following command:
```bash
./scripts/test.sh
```
**NOTE:**  
This experimentation will take **several hours** due to the **native multiplication of 10,000 x 10,000 matrices**.
